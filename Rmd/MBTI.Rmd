---
title: "MBTI dataset transformation and analysis"
author: "Vedran Moškov, Lucija Runjić, Borna Josipović, Lana Bartolović"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
urlcolor: blue
---

```{r setup, include=FALSE, warning=F}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(magrittr)
library(gridExtra)
library(nortest)
library(leaps)
library(RColorBrewer)
library(knitr)
library(nnet)
library(neuralnet)
```

```{r, echo=F}
rm(list = ls()) # uklanjanje svih varijabli iz okoline
```

```{r, echo=F}
source("../Rscripts/utils.R")
```

***

# Motivacija i opis problema

Istražujemo povezanost između osobnosti, dobivene kroz MBTI test, i fizičkih karakteristika poput držanja tijela, težine i visine. Kroz proučavanje pitanja kao što su "Kako tipovi ličnosti utječu na način držanja?" i "Postoje li razlike u tjelesnoj težini ili visini između različitih tipova ličnosti?" analizom ovih podataka, nastojimo bolje razumjeti veze između mentalnog i fizičkog aspekta individualnosti.

***

# Učitavanje i uređivanje podatkovnog skupa

## Učitavanje i proučavanje podatkovnog skupa 

Učitavamo podatkovni skup u varijablu "dataset".
```{r, message=F}
dataset <- read_csv("../data/MBTI.csv")
```

Proučavamo podatkovni skup kako bi ga znali urediti na način da nam je lakše raditi s njim kasnije.
```{r}
head(dataset)
tail(dataset)
glimpse(dataset)
```
\
\
\
\
\
\
\
\
\
\

## Uređivanje podataka podatkovnog skupa

Faktoriziramo i modificiramo stupce "SEX", "ACTIVITY LEVEL", "MBTI", "POSTURE"  kako bismo kasnije mogli lakše grupirati podatke i bolje ih analizirati.
```{r}
dataset$SEX <- as.factor(dataset$SEX)
dataset$`ACTIVITY LEVEL` <- as.factor(dataset$`ACTIVITY LEVEL`)
dataset$`ACTIVITY LEVEL` <- factor(
  dataset$`ACTIVITY LEVEL`, levels = c("Low", "Moderate", "High")
  )
dataset$MBTI <- as.factor(dataset$MBTI)
dataset$POSTURE <- as.factor(dataset$POSTURE)
dataset$POSTURE <- factor(dataset$POSTURE, levels = c("A", "B", "C", "D"), 
                          labels = c("idealno", "kifoza/lordoza", "ravna leđa", "nagnuto"))
```

Uklonit ćemo prva dva stupca podatkovnog skupa obzirom da su jedinstveni identifikatori te nam ne pomažu u analizi.
```{r}
dataset$...1 <- NULL
dataset$`S No` <- NULL
```

Preimenovat ćemo stupce "ACTIVITY LEVEL", "PAIN 1", "PAIN 2", "PAIN 3" i "PAIN 4" radi jednostavnosti.
```{r}
colnames(dataset)[5] <- "ACTIVITY_LEVEL"
colnames(dataset)[6] <- "PAIN_1"
colnames(dataset)[7] <- "PAIN_2"
colnames(dataset)[8] <- "PAIN_3"
colnames(dataset)[9] <- "PAIN_4"
```

Pretvorit ćemo podatke u stupcima "HEIGHT" i "WEIGHT" u centimentri i kilograme.
```{r}
dataset$HEIGHT <- round(dataset$HEIGHT * 2.54, 1)
dataset$WEIGHT <- round(dataset$WEIGHT * 0.45359237, 1)
```


Dodat ćemo neke nove stupce pomoću kojih ćemo grupirati podatke u manje grupe kako bismo ih mogli bolje analizirati.
```{r}
dataset$GROUP <- as.factor(color(dataset$MBTI)) 
dataset$IS_ACTIVE <- as.factor(
  ifelse(dataset$ACTIVITY_LEVEL == "Low", "Inactive", "Active")
  )
dataset$IE <- as.factor(substring(dataset$MBTI, 1, 1))
dataset$SN <- as.factor(substr(dataset$MBTI, 2, 2))
dataset$TF <- as.factor(substr(dataset$MBTI, 3, 3))
dataset$JP <- as.factor(substr(dataset$MBTI, 4, 4))
```
\
\
\
\
\
\
\
Ovako naš podatkovni skup izgleda nakon uređivanja njegovih podataka.
```{r}
head(dataset)
tail(dataset)
glimpse(dataset)
```
***
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\

# Analiza podatkovnog skupa

## Veza između tipa ličnosti i načina držanja

U našem podatkovnom skupu imamo stupce "POSTURE" koji predstavlja kategorije načina držanja i poprima vrijednosti "idealno", "kifoza/lordoza", "ravna leđa" i "nagnuto".

```{r}
ggplot(dataset, aes(x = POSTURE, fill = POSTURE)) +
  geom_bar(color = "black") +
  scale_fill_ordinal() + 
  labs(x = "Posture", fill = "Posture", y = "Count") +
  theme_classic() +
  theme(legend.position = "none")
```
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
Također imamo stupac "MBTI" koji predstavlja tipove ličnosti i razlikujemo [16 vrsta tipova osobnosti](https://www.16personalities.com/personality-types).
```{r}
ggplot(dataset, aes(x = MBTI, fill = MBTI)) + 
  geom_bar(color = "black") + 
  scale_fill_ordinal() + 
  theme_void() +
  theme(axis.text.x = element_text(angle = 45), legend.position = "none") + 
  labs(y = "Count")
```                                                                                      
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
Tih 16 tipova osobnosti radi lakšeg prikaza i analize grupiramo u 4 podskupine u skladu sa [Myers-Briggsovim modelom](https://www.16personalities.com/articles/our-theory) (analiziramo samo prvo slovo tipa osobnosti):
```{r}
ggplot(dataset, aes(x = GROUP, fill = GROUP)) + 
  geom_bar(color = "black") + 
  scale_fill_ordinal() + 
  labs(x = "Group", fill = "Group", y = "Count") +
  theme_classic() + 
  theme(legend.position = "none")
```
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
Vizualiziramo podatke iz stupca "POSTURE" u odnosu na podatke iz stupca "GROUP" kako bismo vidjeli ima li veze između tipa ličnosti i načina držanja.

```{r}
mosaicplot(table(dataset$POSTURE, dataset$GROUP), 
           main = "Mosaic Plot for POSTURE i GROUP",
           color = brewer.pal(4, "Dark2"))
```

Provest ćemo hi kvadrat test za dvije kategorijske varijable gdje ćemo proučavati stupce "POSTURE" i "IE" (introvert/ekstrovert) podatkovnog okvira. 

Prije nego krenemo s testom, moramo provjeriti imamo li uvjete za njegovu provedbu. Najmanja očekivana vrijednost svake ćelije mora biti veća ili jednaka 5, a to provjeravamo pomoću funkcije "check_expected".

Hipoza testa je da su varijable nezavisne, a alternativna hipoteza je da su varijable zavisne.
\
\
H0: POSTURE i IE su nezavisne varijable
  
H1: POSTURE i IE su zavisne varijable
```{r}
contingency_table <- table(dataset$POSTURE, dataset$IE)
kable(contingency_table, caption = "Kontingencijska tablica za POSTURE i IE", align = "r")
check_expected(contingency_table)
```
```{r}
chisq <- chisq.test(contingency_table)
chisq
```
Provedbom hi kvadrat testa dobivamo iznimno maleni p-value, iz čega slijedi da odbacujemo nultu hipotezu uz razinu značajnosti od 0.2 i odbacujemo nultu hipotezu te zaključujemo da su ekstrovertnost i način držanja zavisne varijable

Isti postupak ćemo ponoviti i za raspoznavanje/intuiciju.
\
\
H0: POSTURE i SN su nezavisne varijable

H1: POSTURE i SN su zavisne varijable
```{r}
contingency_table <- table(dataset$POSTURE, dataset$SN)
kable(contingency_table, caption = "Kontingencijska tablica za POSTURE i SN", align = "r")
check_expected(contingency_table)
```
```{r}
chisq <- chisq.test(contingency_table)
chisq
```
Hi kvadrat test nam u ovom slučaju daje p-value od 0.7, iz čega slijedi da ne možemo odbaciti nultu hipotezu te zaključujemo da raspoznavanje/intuicija i način držanja ne ovise jedno o drugome.

## Veza između fizičke aktivnosti i razine ekstrovertiranosti

Fizičku aktivnost nam predstavlja stupac "ACTIVITY_LEVEL":
```{r}
ggplot(dataset, aes(x = IS_ACTIVE, fill = IS_ACTIVE)) + 
  geom_bar(color = "black") + 
  scale_fill_ordinal() + 
  labs(x = "Activity level", fill = "Activity level", y = "Count") +
  theme_classic() +
  theme(legend.position = "none")
```
Prema ovom grafu ljude dijelimo u fizički aktivne i one neaktivne.
\
\
\
\
\

Za koeficijent ekstrovertnosti imamo stupac sa nazivom "E":
```{r}
ggplot(dataset, aes(x = E, fill = E > I)) +
  geom_bar(color = "black") + 
  scale_fill_ordinal() + 
  labs(x = "Extroversion", fill = "Extrovert", y = "Count") +
  scale_y_continuous(breaks = seq(0, 10, 2)) + 
  theme_bw()
```
Na grafu vidimo raspodjelu ljudi koji imaju veći koeficijent ekstrovertnosti od koeficijenta introvertnosti.
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
Provest ćemo hi kvadrat test za kategorijske podatke gdje ćemo proučavati stupce "IS_ACTIVE" (stupac koji mjeri razinu aktivnosti osobe) i "IE" (introvert/ekstrovert) podatkovnog okvira.
```{r}
contingency_table <- table(dataset$IS_ACTIVE, dataset$IE)
kable(contingency_table, caption = "Kontingencijska tablica za IS_ACTIVE i IE", align = "r")
check_expected(contingency_table)
```
```{r, warning=F}
chisq <- chisq.test(contingency_table)
chisq
```
Na temelju rezultata testa zaključujemo da ne postoji veza između fizičke aktivnosti i ekstroverstnosti.

Sada ćemo provesti t-test gdje ćemo usporediti srednje vrijednosti stupca "E" (koeficijent ekstrovertnosti) za fizički aktivne i neaktivne osobe, kako bi usporedili rezultate t-testa s dobivenim rezultatima hi kvadrat testa.

Prije provedbe t-testa provest ćemo f-test kako bi provjerili jednakost varijanci pošto su one nepoznate.
\
\
H0: varijance su jednake
  
H1: varijance nisu jednake
```{r}
f_test <- var.test(E ~ IS_ACTIVE, data = dataset)
f_test
```
Provedbom f-testa dobili smo p-value od 0.8948 na temelju kojeg uz razinu značajnosti 0.2 ne odbacujemo nultu hipotezu te zaključujemo da su varijance jednake.

Sada ćemo provesti t-test:
```{r}
t_test <- t.test(E ~ IS_ACTIVE, data = dataset, var.equal = TRUE)
t_test
```
Na temelju rezultata t-testa ne odbacujemo nultu hipotezu te zaključujemo da ne postoji statistički značajna razlika između srednjih vrijednosti koeficijenta ekstrovertnosti za fizički aktivne i neaktivne osobe, što je u skladu s rezultatima hi kvadrat testa koji nam kaže da ne postoji veza između fizičke aktivnosti i ekstrovertnosti.
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\

## Razlika u visini/težini obzirom na tip ličnosti

U našem podatkovnom skupu imamo stupce "WEIGHT", "HEIGHT", "GROUP" (stupac u kojem je 16 tipova osobnosti raspoređeno u 4 grupe) te stupac "IE" (u kojem je sadržan podatak o tome je li osoba introvert ili ekstrovert) koje ćemo koristiti u analiziranju visine i težine obzirom na tip ličnosti.

Prvo ćemo provjeriti normalnost numeričkih varijabli "HEIGHT" i "WEIGHT koje ćemo koristiti tokom analize.

```{r}
qqnorm(dataset$HEIGHT, main = "QQ Plot of HEIGHT variable")
qqline(dataset$HEIGHT, col = "red", lwd = 2)
```
\
\
\
\
\
\
\
\
\
\
\
\
```{r}
qqnorm(dataset$WEIGHT, main = "QQ Plot of WEIGHT variable")
qqline(dataset$WEIGHT, col = "red", lwd = 2)
```

Iz grafova možemo naslutiti kako se radi o naizgled normalno distribuiranim varijablama.

Pogledajmo sada konkretne p-vrijednosti Shapiro-Wilkovog testa normalnosti kako bi ustanovili pripadaju li ove varijable uistinu normalnoj distribuciji.

Provjerimo prvo varijablu HEIGHT:
\
\
H0: Varijabla je normalno distribuirana

H1: Varijabla nije normalno distribuirana

```{r}
shapiro.test(dataset$HEIGHT)
```
Shapiro-Wilkov test normalnosti nam daje p-vrijednost 0.1028 uz razinu značajnosti 0.2, što znači da odbacujemo nultu hipotezu i zaključujemo kako varijabla HEIGHT nije normalno distribuirana
\
\
\
\
Provedimo isti test za varijablu WEIGHT:
\
\
H0: Varijabla je normalno distribuirana

H1: Varijabla nije normalno distribuirana

```{r}
shapiro.test(dataset$WEIGHT)
```
Za varijablu WEIGHT Shapiro-Wilkov test normalnosti nam daje p-vrijednost od 0.81, što znači da uz razinu značajnosti 0.2 ne možemo odbaciti nultu hipotezu i zaključujemo da je varijabla WEIGHT uistinu normalno distribuirana.

Iako varijabla HEIGHT nije normalna osim što njen histogram donekle nalikuje na normalnu distribuciju, pozivamo se na robusnost ANOVA testa i T-testa te ga ipak provodimo na podacima uz pretpostavku da su podaci nezavisni stoga ćemo nad rezultatima tih testova i donositi zaključke

### Usporedba srednjih visina za četiri grupe osobnosti

Za usporedbu srednjih visina za četiri grupe osobnosti primijenit ćemo analizu varijance (ANOVA) na naš podatkovni skup kako bismo usporedili srednje vrijednosti visine za četiri grupe osobnosti.

Postavljamo hipoteze, neka je mi-i prosječna vrijednost visina. Osobnosti su grupirane u četiri skupine: "Analysts", "Diplomats", "Explorers" i "Sentinels".
\
\
H0: mi1 = mi2 = mi3 = mi4
  
H1: barem dva mi-i nisu jednaka.
\
\
Za hipoteze postavljene na ovaj način, nije preporučljivo koristiti t-test više puta zbog povećanja rizika od greške tipa I. 

Stoga smo odabrali ANOVA (Analiza varijance) kao odgovarajuću metodu.

ANOVA se primjenjuje uz pretpostavke normalnosti distribucije reziduala, jednakih varijanci između grupa i nezavisnosti podataka unutar grupa.

Prije provedbe ANOVA-e moramo pokazati da su varijance grupa jednake.
\
\
Proučimo varijance visina za pojedine grupe osobnosti:
```{r}
vars_height <- aggregate(HEIGHT ~ GROUP, data = dataset, var)
vars_height
```


Provest ćemo Bartlettov test o jednakosti varijanci koji testira hipoteze:
\
\
H0: varijance su jednake.

H1: barem dvije varijance nisu jednake.
  
```{r}
bartlett.test(HEIGHT ~ GROUP, data = dataset)
```
Vidimo da je p-vrijednost velika te zato ne odbacujemo nultu hipotezu te zaključujemo da su varijance među grupama jednake.

Sada smo sigurni da možemo provesti ANOVA-u.

Na sljedećem grafu možemo vidjeti distribucije pojedinih grupa osobnosti s obzirom na njihove visine.
```{r}
ggplot(dataset, aes(x = HEIGHT, fill = GROUP)) + 
  geom_bar(color = "black", alpha = 0.75) + 
  labs(x = "Height", y = "Count", fill = "") + 
  scale_y_continuous(breaks = seq(0, 10, 2)) +
  scale_fill_ordinal() +
  theme_bw()
```

```{r}
ggplot(dataset, aes(x = GROUP,y = HEIGHT)) + 
  geom_boxplot() + 
  labs(x = "Personality groups", 
       y = "Height", 
       title = "Box-plots of height by personality group") +
  theme_bw()
```
Iz ovog grafa možemo vidjeti distribucije pojedinih grupa osobnosti u obliku box-plota iz kojih dobijemo vizualnu reprezentaciju njihovih medijana i interkvartilnih rangova. 

Možemo vidjeti kako su medijani grupa "Analysts" i "Explorers" na rubu granica interkvartilnog ranga grupe "Sentinels", stoga ovdje možemo očekivati neke probleme oko jednakosti sredina i standardnih devijacija ovih grupa.

Pogledajmo srednje vrijednosti visina za pojedine grupe osobnosti:
```{r}
means_height <- aggregate(HEIGHT ~ GROUP, data = dataset, mean)
means_height
```
\
\
\
\
Sada provedimo test:

```{r}
model <- aov(HEIGHT ~ GROUP, data = dataset)
summary(model)
```
Obzirom na p-vrijednost od 0.47 ne odbacujemo nultu hipotezu. To sugerira da nema dovoljno dokaza za zaključak da postoje značajne razlike u prosječnoj visini između četiri skupine osobnosti.


### Usporedba srednjih težina za ekstroverte i introverte

Obzirom da u ovom koraku varijablu WEIGHT grupiramo u dvije grupe, težine ekstroverata i introverata, također moramo i provjeriti je li varijabla WEIGHT normalno distribuirana za svaku grupu.
```{r}
weight_extroverts <- subset(dataset, IE == "E")$WEIGHT
weight_introverts <- subset(dataset, IE == "I")$WEIGHT
```
```{r}
qqnorm(weight_extroverts, main = "QQ Plot of HEIGHT variable for extroverts")
qqline(weight_extroverts, col = "red", lwd = 2)
```
```{r}
qqnorm(weight_introverts, main = "QQ Plot of HEIGHT variable for introverts")
qqline(weight_introverts, col = "red", lwd = 2)
```
Sada provodimo Shapiro-Wilkov test normalnosti varijable HEIGHT za svaku grupu:
```{r}
shapiro.test(weight_extroverts)
```
Uz dobiveni p-value od 0.96 i razinu značajnosti od 0.2 ne odbacujemo nultu hipotezu te zaključujemo da je varijabla HEIGHT normalno distribuirana za grupu ekstroverata.

```{r}
shapiro.test(weight_introverts)
```
Dobiveni p-value za WEIGHT za introverte iznosi 0.1261 što je manje od 0.2, stoga odbacujemo nultu hipotezu te zaključujemo da varijabla HEIGHT nije normalno distribuirana za grupu introverata, no pozivamo se na robusnost t-testa na normalnost podataka.


Na sljedećem grafu možemo vidjeti distribuciju introverata/ekstroverata obzirom na njihove težine.
```{r}
ggplot(dataset, aes(x = WEIGHT, fill = IE)) + 
  geom_histogram(color = "black", bins = 30, alpha = 0.75) + 
  labs(x = "Height", y = "Count", fill = "") + 
  scale_y_continuous(breaks = seq(0, 10, 2)) +
  scale_fill_ordinal(labels = c("Extrovert", "Introvert")) + 
  theme_bw()
```
Sada ćemo usporediti srednje vrijednosti težina ekstroverata i introverata koristeći stupce "IE" i "WEIGHT" koristeći t-test.

Prije provedbe t-testa moramo provesti F-test da provjerimo jednakost varijanci budući da su nepoznate.
\
\
Pogledajmo prije varijance težina introverata:
```{r}
vars_weight <- aggregate(WEIGHT ~ IE, data = dataset, var)
vars_weight
```
F-test ćemo provesti sa hipotezama:
\
\
H0: varijance su jednake
  
H1: varijance nisu jednake
  
```{r}
f_test <- var.test(HEIGHT ~ IE, data = dataset)
f_test
```
F-test daje p-vrijednost 0.6418 te zaključujemo da su varijance jednake.

Sada možemo provesti T-test uz jednake, ali nepoznate varijance.

Pogledajmo srednje vrijednosti težina ekstroverata i introverata.
```{r}
means_weight <- aggregate(WEIGHT ~ IE, data = dataset, mean)
means_weight
```


Test provodimo sa hipotezama:
\
\
H0: srednje vrijednosti težine jednake su za ekstroverte i introverte
  
H1: srednje vrijednosti težine nisu jednake za ekstroverte i introverte

```{r}
t_test <- t.test(HEIGHT ~ IE, data = dataset, var.equal = TRUE)
t_test
```
Zbog velike p-vrijednosti ne odbacujemo nultu hipotezu te zaključujemo da su srednje vrijednosti visina za introverte i ekstroverte jednake.


## Tip ličnosti na temelju pojedinih karakteristika

Sada ćemo pokušati predvidjeti tip ličnosti na temelju pojedinih karakteristika.

Ne možemo izračunati točnu vezu s MBTI tipom osobnosti jer je to diskretna varijabla, stoga ćemo pokušavati predvidjeti koeficijente za pojedino svojstvo (npr. ekstrovertnost, intuitivnost, itd.) koristeći linearnu regresiju i uspoređivanjem dobivenih koeficijenata za isto svojstvo, u našem primjeru za J (prosuđivanje) i P (opažanje). 

Osoba pripada kategoriji J ili P ovisno o tome koji je koeficijent (predviđan linearnom regresijom) veći. 

Najprije je potrebno testirati više modela linearne regresije odabirom različitih regresora kako bi prinašli najbolji model.

Za pojedine modele moramo izračunati R^2 vrijednost, koja nam govori koliko dobro model objašnjava varijabilnost podataka. Model s najvećom R^2 vrijednosti je najbolji model.

Nakon što odaberemo najbolji model, izračunat ćemo koeficijente za J i P, te na temelju njih odrediti tu kategoriju.

```{r}
print("Prvi model za J i P karakteristike")
model <- lm(formula = dataset$J ~ dataset$HEIGHT + 
              dataset$SEX + 
              dataset$AGE
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova J prvim modelom", r_squared))

model <- lm(formula = dataset$P ~ dataset$HEIGHT + 
              dataset$SEX + 
              dataset$AGE
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova P prvim modelom", r_squared))

print("Drugi model za J i P karakteristike")
model <- lm(formula = dataset$J ~ dataset$HEIGHT + 
    dataset$WEIGHT + 
    dataset$SEX + 
    dataset$AGE + 
    dataset$ACTIVITY_LEVEL
  )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova J drugim modelom", r_squared))

model <- lm(formula = dataset$P ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              dataset$AGE + 
              dataset$ACTIVITY_LEVEL
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova P drugim modelom", r_squared))

print("Treci model za J i P karakteristike")
model <- lm(formula = dataset$J ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              dataset$AGE + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova J trecim modelom", r_squared))

model <- lm(formula = dataset$P ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              dataset$AGE + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova P trecim modelom", r_squared))
```
Vidimo kako je najprikladniji ispao treći model jer ima najveće R kvadrat vrijednosti u iznosima od 0.2055 za predikciju karakteristike J i 0.1817 za predikciju karakteristike P. 

Testirajmo sada točnost modela
```{r}
model <- lm(formula = dataset$J ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              dataset$AGE + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
probs1 <- predict(model, newdata = dataset, type = "response")

model <- lm(formula = dataset$P ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              dataset$AGE + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
probs2 <- predict(model, newdata = dataset, type = "response")

slova <- ifelse(probs1>probs2, "J", "P")
vrijednosti <- ifelse(slova == substr(dataset$MBTI, 4, 4), 1, 0)
uk <- sum(vrijednosti)/length(vrijednosti)

print(paste("Točnost", uk))
```

Kod procjene pripada li osoba kategoriji J ili P, dobili smo točnost od 0.6289, što je zadovoljavajuće. Ovo je dobar rezultat s obzirom na to da je naš model bio jednostavan odnosno nije sadržavao puno regresora. Još jedan problem na koji smo naišli je bila činjenica da podaci nisu bili ujednačeni, to jest određenih osobnosti nije bilo željene količine. 

Ponovimo testiranje za još jednu karaktristiku, npr. razmišljanje i osjećanje

```{r}
print("Prvi model za F i T karakteristike")
model <- lm(formula = dataset$F ~ dataset$HEIGHT + 
              dataset$SEX + 
              dataset$AGE
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova F prvim modelom", r_squared))

model <- lm(formula = dataset$T ~ dataset$HEIGHT + 
              dataset$SEX + 
              dataset$AGE
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova T prvim modelom", r_squared))

print("Drugi model za F i T karakteristike")
model <- lm(formula = dataset$F ~ dataset$HEIGHT +
              dataset$WEIGHT + 
              dataset$SEX + 
              log(dataset$AGE) + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 +
              dataset$PAIN_4
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova F drugim modelom", r_squared))

model <- lm(formula = dataset$T ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              log(dataset$AGE) + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova T drugim modelom", r_squared))

print("Treci model za F i T karakteristike")
model <- lm(formula = dataset$F ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              dataset$AGE + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 + 
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova F trecim modelom", r_squared))

model <- lm(formula = dataset$T ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX +
              dataset$AGE +
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 +
              dataset$PAIN_2 + 
              dataset$PAIN_3 +
              dataset$PAIN_4
            )
model_summary <- summary(model)
r_squared <- model_summary$r.squared
print(paste("R kvadrat za predikciju slova T trecim modelom", r_squared))

```
Drugi i treći modeli su znatno bolji od prvog, što je i očekivano s obzirom na to da su sadržavali više regresora, no treći model se ipak pokazao malo bolji od drugog.


Testirajmo sada točnost modela
```{r}
model <- lm(formula = dataset$F ~ dataset$HEIGHT + 
              dataset$WEIGHT + 
              dataset$SEX + 
              log(dataset$AGE) + 
              dataset$ACTIVITY_LEVEL + 
              dataset$PAIN_1 + 
              dataset$PAIN_2 +
              dataset$PAIN_3 + 
              dataset$PAIN_4
            )
model_summary <- summary(model)
probs1 <- predict(model, newdata = dataset, type = "response")

model <- lm(formula = dataset$T ~ dataset$HEIGHT +
              dataset$WEIGHT +
              dataset$SEX +
              log(dataset$AGE) +
              dataset$ACTIVITY_LEVEL +
              dataset$PAIN_1 + 
              dataset$PAIN_2 +
              dataset$PAIN_3 +
              dataset$PAIN_4)

model_summary <- summary(model)
probs2 <- predict(model, newdata = dataset, type = "response")

slova <- ifelse(probs1>probs2, "F", "T")
vrijednosti <- ifelse(slova == substr(dataset$MBTI, 3, 3), 1, 0)
uk <- sum(vrijednosti)/length(vrijednosti)

print(paste("Točnost", uk))
```
Točnost danog modela iznosi 70.1%, što je znatno bolje od slučajnog odabira te smatramo to dovoljno dobrom predikcijom.
\
\
\
\
Sada ćemo pomoću logističke regresije pokušati predvidjeti skupinu MBTI tipa na temelju ostalih varijabli.

Prisjetimo se, skupine MBTI tipova su "Analysts", "Diplomats", "Explorers" i "Sentinels".

Model logističke regresije na temelju danih varijabli izbacuje vektor vrijednosti veličine c što je u našem slučaju 4 pošto imamo 4 različita MBTI tipa. 

Svaka od tih vrijednosti je pomoću funkcije `softmax` preslikana na interval [0, 1] gdje suma svih vjerojatnosti za pojedine klase iznosi 1. 

Taj vektor se zatim provodi "ubacuje" u funkciju `argmax` koja vektor enkodira tzv. "one-hot" encodingom, koji ima vrijednost 1 na indeksu najveće vrijednosti, a 0 na ostalim indeksima. 

Taj vektor se konačno uspoređuje s vektorom stvarnih vrijednosti i računa se točnost modela.

U našim modelima ćemo dodati jedan skriveni sloju, a parametar `linear.output` postaviti na `TRUE` kako bi se klasična sigmoidalna funkcija u skrivenom sloju zamijenila linearnom ReLU funkcijom koja u praksi pokazuje bolje rezultate.
\
\
\
\
Definirajmo sada funkciju koja će nam pomoći u evaluaciji modela.

```{r}
evaluate_model <- function(model, dataset) {
  one_hot_encoding <- c("Analysts", "Diplomats", "Explorers", "Sentinels")
  predictions <- predict(model, dataset, type = "response")
  predicted_classes <- max.col(predictions)
  
  accuracy <- sum(one_hot_encoding[predicted_classes] == dataset$GROUP) / length(dataset$GROUP)
  paste0("Točnost modela: ", 100*accuracy %>% round(4), "%")
}
```

Provedimo konačno logističku regresiju na našem skupu podataka.

Prvi model će kao regresore koristiti samo visinu, težinu, dob i spol ispitanika.
```{r}
set.seed(131213121)

encoded_SEX <- ifelse(dataset$SEX == "M", 1, 0)
dataset$encoded_SEX <- encoded_SEX

model <- neuralnet(formula = GROUP ~ HEIGHT + WEIGHT + AGE + encoded_SEX, 
                   data = dataset, 
                   hidden = c(3),
                   linear.output = T,
                   stepmax = 1000,
                   learningrate = 0.01
                   )

evaluate_model(model, dataset)
```
Točnost ovog modela iznosi 35.05%, što je bolje od slučajnog odabira, ali i dalje nedovoljno dobro.


Drugi model će kao regresore koristiti PAIN_1, PAIN_2, PAIN_3 i PAIN_4, koji predstavljaju bol u vratu, bol u gornjem dijelu leđa, bol u srednjem dijelu leđa i bol u donjem dijelu leđa, respektivno.
```{r}
set.seed(1312131)

model <- neuralnet(formula = GROUP ~ PAIN_1 + PAIN_2 + PAIN_3 + PAIN_4, 
                   data = dataset, 
                   hidden = c(4, 2),
                   linear.output = T,
                   stepmax = 100000,
                   learningrate = 0.01
                   )

evaluate_model(model, dataset)
```
Iznenađujuće, ovaj model ima točnost od 60.82%, što je znatno bolje od prethodnog modela.

## Je li udio ekstrovertnih ljudi isti kod ljudi iznad i ispod 45 godina

Prije nego krenemo na testiranje, moramo provjeriti je li naša pretpostavka o normalnoj distribuciji podataka točna.
```{r}
qqnorm(dataset$AGE, main = "QQ Plot of AGE variable")
qqline(dataset$AGE, col = "red", lwd = 2)
```
Iz grafa se čini da je pretpostavka o normalnoj distribuciji točna, no provjeravamo tu hipotezu i Shapiro-Wilkovim testom o normalnosti.
```{r}
shapiro.test(dataset$AGE)
```
Uz p-value od 0.068 uz razinu značajnosti od 0.2 odbacujemo nultu hipotezu i zaključujemo da varijabla AGE nije normalno distribuirana.

Iako varijabla AGE nije normalno distribuirana, poznato nam je da su z-test i t-test robusni na normalnost podataka, pa ćemo ih koristiti za testiranje.

Također, poznavajući centralni granični teorem, znamo da će se uz dovoljno veliki uzorak, distribucija srednjih vrijednosti približiti normalnoj distribuciji, stoga ćemo koristiti z-test za testiranje.

Kako bismo testirali je li postotak ekstroverata isti kod mladjih i starijih ljudi, koristit ćemo Z-test za dvije proporcije, uz alfa=0.05, a hipoteze postavljamo ovako
\
\
H0 : postotak ekstroverata je isti neovisno o godinama (p1 - p2 = 0)

H1 : postotak ekstroverata se razlikuje ovisno o godinama (p1 - p2 != 0)

```{r}
subset_result <- subset(dataset, AGE < 46 & substr(MBTI, 1, 1) == "E")
Eyoung <- nrow(subset_result)
total_group1 <- sum(dataset$AGE <= 45)

subset_result <- subset(dataset, AGE > 45 & substr(MBTI, 1, 1) == "E")
Eold <- nrow(subset_result)
total_group2 <- sum(dataset$AGE > 45)

# Perform the z-test for proportions
z_test_result <- prop.test(c(Eyoung, Eold),
                           c(total_group1, total_group2),
                           alternative = "two.sided")

# Print the result
print(z_test_result)
```
Provedeni z-test nam daje p-value 0.5667 koji je znatno veći od razine značajnosti 0.2 iz čega zaključujemo kako na temelju ovih podataka nemamo razloga sumnjati u H0 stiga ju niti ne odbacujemo.
***

# Zaključak
(---prazan prostor za zaključak---)


